{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchvision import datasets \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import timm\n",
    "\n",
    "\n",
    "class cfg:\n",
    "    datadir = './data'\n",
    "    img_size = 256 \n",
    "    batch_size = 128\n",
    "    model_name = 'resnet18'\n",
    "    num_classes = 10 \n",
    "    lr = 1e-3 \n",
    "    epochs = 50\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Resize((cfg.img_size,cfg.img_size))]\n",
    ")    \n",
    "    \n",
    "\n",
    "trainset = datasets.CIFAR10(root      = cfg.datadir,\n",
    "                            train     = True,\n",
    "                            transform = transform,\n",
    "                            download  = True\n",
    "                            )\n",
    "testset  = datasets.CIFAR10(root      = cfg.datadir,\n",
    "                            train     = False,\n",
    "                            transform = transform,\n",
    "                            download  = True\n",
    "                            )\n",
    "\n",
    "trainloader, testloader = DataLoader(trainset, batch_size = cfg.batch_size, shuffle=True), DataLoader(testset, batch_size = cfg.batch_size, shuffle=False)\n",
    "\n",
    "net = timm.create_model(model_name = cfg.model_name, pretrained = True, num_classes = cfg.num_classes)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | train_accuracy : 0.29096 | test_accuracy : 0.2726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def train_step(net, optimizer, criterion, trainloader):\n",
    "        net.train()\n",
    "        optimizer.zero_grad() \n",
    "    \n",
    "        predict = [] \n",
    "        target = [] \n",
    "        for imgs, labels in trainloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            \n",
    "            output = net(imgs)\n",
    "            loss = criterion(output,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            \n",
    "            predict.append(output.argmax(1).detach().cpu().numpy())\n",
    "            target.append(labels.detach().cpu().numpy())\n",
    "\n",
    "        \n",
    "        target = np.concatenate(target)\n",
    "        predict = np.concatenate(predict)        \n",
    "        train_accuracy = accuracy_score(target,predict)\n",
    "        return train_accuracy\n",
    "    \n",
    "def valid_step(net, testloader, criterion):\n",
    "        net.eval()\n",
    "        predict = [] \n",
    "        target = [] \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in testloader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                output = net(imgs)\n",
    "                loss = criterion(output, labels)\n",
    "                predict.append(output.argmax(1).detach().cpu().numpy())\n",
    "                target.append(labels.detach().cpu().numpy())\n",
    "                \n",
    "        target = np.concatenate(target)\n",
    "        predict = np.concatenate(predict)        \n",
    "        test_accuracy = accuracy_score(target,predict)\n",
    "        return test_accuracy\n",
    "    \n",
    "for epoch in range(cfg.epochs):\n",
    "    \n",
    "    # Train\n",
    "    train_accuracy = train_step(net, optimizer, criterion, trainloader)\n",
    "    \n",
    "    # Test \n",
    "    test_accuracy = valid_step(net, testloader, criterion)\n",
    "    \n",
    "    print(f'Epoch : {epoch} | train_accuracy : {train_accuracy} | test_accuracy : {test_accuracy}')\n",
    "            \n",
    "    break \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignite Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | train_accuracy : 0.31758 | test_accuracy : 0.3342\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import Accuracy\n",
    "\n",
    "def train_step(net, optimizer, criterion, trainloader):\n",
    "        net.train()\n",
    "        optimizer.zero_grad() \n",
    "    \n",
    "        acc_metric = Accuracy()\n",
    "        for imgs, labels in trainloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            \n",
    "            output = net(imgs)\n",
    "            loss = criterion(output,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            \n",
    "            acc_metric.update(\n",
    "                                (output,labels)\n",
    "                                )\n",
    "\n",
    "        \n",
    "        train_accuracy = acc_metric.compute()\n",
    "        return train_accuracy\n",
    "    \n",
    "def valid_step(net, testloader, criterion):\n",
    "        net.eval()\n",
    "        \n",
    "        val_acc_metric = Accuracy()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in testloader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                output = net(imgs)\n",
    "                loss = criterion(output, labels)\n",
    "                \n",
    "                val_acc_metric.update(\n",
    "                                        (output, labels)\n",
    "                                        )\n",
    "                \n",
    "        test_accuracy = val_acc_metric.compute()\n",
    "        return test_accuracy\n",
    "    \n",
    "for epoch in range(cfg.epochs):\n",
    "    \n",
    "    # Train\n",
    "    train_accuracy = train_step(net, optimizer, criterion, trainloader)\n",
    "    \n",
    "    # Test \n",
    "    test_accuracy = valid_step(net, testloader, criterion)\n",
    "    \n",
    "    print(f'Epoch : {epoch} | train_accuracy : {train_accuracy} | test_accuracy : {test_accuracy}')\n",
    "            \n",
    "    break \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignite Engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | train_accuracy : 0.34938 | test_accuracy : 0.3685\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Accuracy\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "def train(engine, batch):\n",
    "    net.train()\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    imgs, labels = batch[0].to(device), batch[1].to(device)        \n",
    "    \n",
    "    output = net(imgs)\n",
    "    loss = criterion(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()   \n",
    "    \n",
    "    acc_metric.update(\n",
    "            (output,labels)\n",
    "            )\n",
    "\n",
    "    return loss.item()  \n",
    "\n",
    "def valid(engine, batch):\n",
    "    net.eval()\n",
    "    imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(imgs)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "    val_acc_metric.update(\n",
    "        (output, labels)\n",
    "    )\n",
    "    \n",
    "\n",
    "trainer = Engine(train)\n",
    "evaluator = Engine(valid)\n",
    "\n",
    "for epoch in range(cfg.epochs):\n",
    "    \n",
    "    # Train    \n",
    "    acc_metric = Accuracy()\n",
    "    trainer.run(trainloader)        \n",
    "    train_accuracy = acc_metric.compute()\n",
    "    \n",
    "    # Test \n",
    "    val_acc_metric = Accuracy()\n",
    "    evaluator.run(testloader)\n",
    "    valid_accuracy = val_acc_metric.compute()\n",
    "            \n",
    "    test_accuracy = val_acc_metric.compute()\n",
    "    print(f'Epoch : {epoch} | train_accuracy : {train_accuracy} | test_accuracy : {test_accuracy}')\n",
    "            \n",
    "    break \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignite API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: [100/391]  26%|██▌        [00:24<01:11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 : 100 - batch loss: 1.653, lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: [200/391]  51%|█████      [00:49<00:47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 : 200 - batch loss: 1.723, lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: [300/391]  77%|███████▋   [01:14<00:22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 : 300 - batch loss: 1.639, lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 391\n",
       "\tepoch: 1\n",
       "\tepoch_length: 391\n",
       "\tmax_epochs: 1\n",
       "\toutput: 1.6260793209075928\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.engine.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Accuracy\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "def train(engine, batch):\n",
    "    net.train()\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    imgs, labels = batch[0].to(device), batch[1].to(device)        \n",
    "    \n",
    "    output = net(imgs)\n",
    "    loss = criterion(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    \n",
    "    return loss.item()  \n",
    "\n",
    "def valid(engine, batch):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        y_pred = net(x)\n",
    "    return y_pred, y\n",
    "\n",
    "trainer = Engine(train)\n",
    "evaluator = Engine(valid)\n",
    "Accuracy().attach(evaluator, \"accuracy\")\n",
    "ProgressBar().attach(trainer)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=100))\n",
    "def log_training(engine):\n",
    "    batch_loss = engine.state.output\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    e = engine.state.epoch\n",
    "    n = engine.state.max_epochs\n",
    "    i = engine.state.iteration\n",
    "    print(f\"Epoch {e}/{n} : {i} - batch loss: {batch_loss:.3f}, lr: {lr}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=1))\n",
    "def run_validation():\n",
    "    evaluator.run(testloader)\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=1))\n",
    "def log_validation():\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(metrics['accuracy'])\n",
    "    \n",
    "trainer.run(trainloader, max_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
